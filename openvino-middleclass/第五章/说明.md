性能评估与硬件选择

一.推理流程如下图：
![0828102311](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/0828102311.png)

吞吐量：吞吐量表示神经网络在一秒内可以处理的帧数，通过FPS每秒帧数来衡量吞吐量的大小

二.在特定设备上影响神经网络性能的因素：

1.神经网络本身的拓扑或架构，比如各层之间的连接，内存消耗，图像输入大小等都是主要因素，因此需要选择一个合适的网络

2.目标设备的不同，也会影响神经网络性能。选择适合的设备，要综合考虑价格，功耗范围等因素

![0828103950](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/0828103950.png)

3.模型精度
- 在特定设备上选择最合适的模型精度
- 优化运行时间和图像大小
- INT8在支持“DL Boost”的系统可以提升性能

Intel指令集架构具有许多数据打包类型，因此你可以使用一种数据打包类型将许多数据打包，然后一次对所有数据移项操作，我们称之为单指令，多数据。

![0828110739](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/0828110739.png)

数据格式能带来的优势，我们要为特定设备选择最佳数据格式，并非所有的设备都支持所有的数据格式，使用较小的数据类型会占用较小的内存空间，并减少操作量和加快执行速度，支持“DL Boost”的系统可以通过“DL Boost”指令来提供额外的性能提升。

![0828113558](https://cdn.jsdelivr.net/gh/luckykang/picture_bed/blogs_images/0828113558.png)

4.批处理
推理引擎可以利用批次为所有的图像只加载一次权重，并帮助提升其他方面的效率，但是大批次也会带来延迟增加和更大的内存占用，因此对于延迟更重要的更多实施用途而言，小批次通常更适合。

5.异步执行
最终我们处理的是视频或者一系列的图像，在同步模式下每个阶段等待流水线完成，这样会降低性能。
另一种方式是，我们可以发送推理请求，而不是等待完成，然后继续准备下一帧或实施其他任务，当推理请求没有阻止执行时，我们可以准备相关帧，并且实施推理操作，这样可以带来吞吐量的巨大提升。

6.cpu的吞吐量模式
cpu的吞吐量模式支持推理引擎在cpu上同时高效运行多个推理请求，从而显著提高吞吐量，推理引擎可以智能分配cpu资源，并可以配置多个推理请求，当然cpu的核心越多，效率就越高。推理引擎支持通过监控并行推理请求的数量、要使用的线程数以及其他功能来控制其执行。
 
7.benchmark_app 使用的模型
ssd-mobilenet   python3 benchmark_app.py -m models/ssd-mobilenet.xml -i images/ -t 20 -api async
resnet-50       python3 benchmark_app.py -m models/resnet-50.xml -i images/ -t 20

